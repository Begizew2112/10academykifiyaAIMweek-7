{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed in successfully as C48; remember to not break the ToS or you will risk an account ban!\n",
      "Connected to Telegram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Server closed the connection: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Attempt 1 at connecting failed: OSError: [Errno 10051] Connect call failed ('149.154.167.91', 443)\n",
      "Attempt 2 at connecting failed: OSError: [Errno 10051] Connect call failed ('149.154.167.91', 443)\n",
      "Attempt 3 at connecting failed: OSError: [Errno 10051] Connect call failed ('149.154.167.91', 443)\n",
      "Attempt 4 at connecting failed: OSError: [Errno 10051] Connect call failed ('149.154.167.91', 443)\n",
      "Attempt 5 at connecting failed: OSError: [Errno 10051] Connect call failed ('149.154.167.91', 443)\n",
      "Attempt 6 at connecting failed: OSError: [Errno 10051] Connect call failed ('149.154.167.91', 443)\n",
      "Attempt 1 at connecting failed: OSError: [Errno 10051] Connect call failed ('149.154.167.91', 443)\n"
     ]
    }
   ],
   "source": [
    "from telethon.sync import TelegramClient\n",
    "\n",
    "# Replace these with your own values\n",
    "api_id = '22908602'\n",
    "api_hash = '20bdd2238cc3dbb7014870281cce444e'\n",
    "phone_number = '+251701425988'\n",
    "\n",
    "# Create the client and connect\n",
    "client = TelegramClient('session_name1', api_id, api_hash)\n",
    "\n",
    "async def connect_telegram():\n",
    "    await client.start(phone_number)\n",
    "    print(\"Connected to Telegram\")\n",
    "\n",
    "await connect_telegram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from telethon.tl.types import PeerChannel\n",
    "\n",
    "import os\n",
    "\n",
    "from telethon import TelegramClient\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from telethon.tl.types import MessageMediaPhoto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "message scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping messages... Collected 0 so far.\n",
      "Scraping messages... Collected 100 so far.\n",
      "Scraping messages... Collected 200 so far.\n",
      "Scraping messages... Collected 300 so far.\n",
      "Scraping messages... Collected 400 so far.\n",
      "Scraping messages... Collected 500 so far.\n",
      "Scraping messages... Collected 600 so far.\n",
      "Scraping messages... Collected 700 so far.\n",
      "Scraping messages... Collected 800 so far.\n",
      "Scraping messages... Collected 900 so far.\n",
      "Scraping messages... Collected 1000 so far.\n",
      "Scraping messages... Collected 1079 so far.\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeVideo' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Error processing media: 'DocumentAttributeAudio' object has no attribute 'file_name'\n",
      "Scraping complete. Data saved to 'scraped_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "async def scrape_channel_messages(channel_username, max_messages=10000, batch_size=100, sleep_time=2):\n",
    "    # Get the channel entity\n",
    "    channel = await client.get_entity(channel_username)\n",
    "\n",
    "    # Variables for scraping\n",
    "    offset_id = 0\n",
    "    all_messages = []\n",
    "\n",
    "    # Extract channel details\n",
    "    channel_title = channel.title if hasattr(channel, 'title') else 'N/A'\n",
    "    channel_id = channel.id\n",
    "\n",
    "    while len(all_messages) < max_messages:\n",
    "        print(f\"Scraping messages... Collected {len(all_messages)} so far.\")\n",
    "\n",
    "        try:\n",
    "            # Fetch the message history\n",
    "            history = await client(GetHistoryRequest(\n",
    "                peer=channel,\n",
    "                offset_id=offset_id,\n",
    "                offset_date=None,\n",
    "                add_offset=0,\n",
    "                limit=batch_size,\n",
    "                max_id=0,\n",
    "                min_id=0,\n",
    "                hash=0\n",
    "            ))\n",
    "\n",
    "            # Break the loop if no more messages are returned\n",
    "            if not history.messages:\n",
    "                break\n",
    "\n",
    "            # Add messages to the list\n",
    "            messages = history.messages\n",
    "            all_messages.extend(messages)\n",
    "\n",
    "            # Update the offset_id to the last message's ID to avoid duplicates\n",
    "            offset_id = messages[-1].id\n",
    "\n",
    "            # Sleep to respect Telegram's rate limit\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fetching messages: {e}\")\n",
    "            break  # Break the loop if there's an error fetching messages\n",
    "\n",
    "    # Limit the number of messages to max_messages\n",
    "    all_messages = all_messages[:max_messages]\n",
    "\n",
    "    # Prepare the data for CSV export\n",
    "    data = []\n",
    "    for msg in all_messages:\n",
    "        try:\n",
    "            if msg.message:  # Only save non-empty messages\n",
    "                media_path = ''\n",
    "                if msg.media:  # Check if there's media\n",
    "                    try:\n",
    "                        # Handle different types of media\n",
    "                        if hasattr(msg.media, 'document'):\n",
    "                            media_path = msg.media.document.attributes[0].file_name\n",
    "                        elif hasattr(msg.media, 'photo'):\n",
    "                            media_path = 'Photo media'\n",
    "                        elif hasattr(msg.media, 'video'):\n",
    "                            media_path = 'Video media'\n",
    "                        else:\n",
    "                            media_path = 'Other media'\n",
    "                    except Exception as media_error:\n",
    "                        print(f\"Error processing media: {media_error}\")\n",
    "                        media_path = 'Error processing media'\n",
    "\n",
    "                data.append({\n",
    "                    'Channel Title': channel_title,\n",
    "                    'Channel Username': channel_username,\n",
    "                    'ID': msg.id,\n",
    "                    'Message': msg.message,\n",
    "                    'Date': msg.date,\n",
    "                    'Media Path': media_path\n",
    "                })\n",
    "\n",
    "        except Exception as msg_error:\n",
    "            print(f\"Error processing message ID {msg.id}: {msg_error}\")\n",
    "\n",
    "    # Convert to DataFrame and save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(r'C:\\Users\\Yibabe\\Desktop\\10academykifiyaAIMweek-7\\data\\scraped_data.csv', index=False)\n",
    "    print(\"Scraping complete. Data saved to 'scraped_data.csv'.\")\n",
    "\n",
    "# Scrape up to 10,000 messages and save to CSV\n",
    "await scrape_channel_messages('@yetenaweg', max_messages=10000, batch_size=100, sleep_time=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping images... Collected 0 so far.\n",
      "Scraping images... Collected 67 so far.\n",
      "Scraping complete. Image data saved to 'image_messages.csv'.\n"
     ]
    }
   ],
   "source": [
    "async def scrape_image_messages(channel_username, max_images=10000, batch_size=100, sleep_time=2):\n",
    "    # Get the channel entity\n",
    "    channel = await client.get_entity(channel_username)\n",
    "    \n",
    "    # Variables for scraping\n",
    "    offset_id = 0\n",
    "    all_images = []\n",
    "\n",
    "    while len(all_images) < max_images:\n",
    "        print(f\"Scraping images... Collected {len(all_images)} so far.\")\n",
    "\n",
    "        # Fetch the message history\n",
    "        history = await client(GetHistoryRequest(\n",
    "            peer=channel,\n",
    "            offset_id=offset_id,\n",
    "            offset_date=None,\n",
    "            add_offset=0,\n",
    "            limit=batch_size,\n",
    "            max_id=0,\n",
    "            min_id=0,\n",
    "            hash=0\n",
    "        ))\n",
    "\n",
    "        # Break the loop if no more messages are returned\n",
    "        if not history.messages:\n",
    "            break\n",
    "\n",
    "        # Add image messages to the list\n",
    "        messages = history.messages\n",
    "        for msg in messages:\n",
    "            if isinstance(msg.media, MessageMediaPhoto):  # Check for photo media\n",
    "                image_url = f\"https://t.me/c/{channel.id}/{msg.id}\"  # Construct the URL to the image\n",
    "                all_images.append({\n",
    "                    'ID': msg.id,\n",
    "                    'Date': msg.date,\n",
    "                    'Image URL': image_url\n",
    "                })\n",
    "\n",
    "        # Update the offset_id to the last message's ID to avoid duplicates\n",
    "        offset_id = messages[-1].id\n",
    "\n",
    "        # Sleep to respect Telegram's rate limit\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    # Limit the number of images to max_images\n",
    "    all_images = all_images[:max_images]\n",
    "\n",
    "    # Convert to DataFrame and save to CSV\n",
    "    df = pd.DataFrame(all_images)\n",
    "    df.to_csv(r'C:\\Users\\Yibabe\\Desktop\\10academykifiyaAIMweek-7\\data\\image_messages.csv', index=False)\n",
    "    print(\"Scraping complete. Image data saved to 'image_messages.csv'.\")\n",
    "\n",
    "# Run the scraping function\n",
    "await scrape_image_messages('@CheMed123', max_images=10000, batch_size=100, sleep_time=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we scrap the telegram channels to get the url of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping images... Collected 0 so far.\n",
      "Scraping images... Collected 67 so far.\n",
      "Scraping complete. Image data saved to 'image_messages.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Directory to save images\n",
    "output_directory = r'C:\\Users\\Yibabe\\Desktop\\10academykifiyaAIMweek-7\\data\\images1'\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "async def scrape_image_messages(channel_username, max_images=10000, batch_size=100, sleep_time=2):\n",
    "    # Get the channel entity\n",
    "    channel = await client.get_entity(channel_username)\n",
    "    \n",
    "    # Variables for scraping\n",
    "    offset_id = 0\n",
    "    all_images = []\n",
    "\n",
    "    while len(all_images) < max_images:\n",
    "        print(f\"Scraping images... Collected {len(all_images)} so far.\")\n",
    "\n",
    "        # Fetch the message history\n",
    "        history = await client(GetHistoryRequest(\n",
    "            peer=channel,\n",
    "            offset_id=offset_id,\n",
    "            offset_date=None,\n",
    "            add_offset=0,\n",
    "            limit=batch_size,\n",
    "            max_id=0,\n",
    "            min_id=0,\n",
    "            hash=0\n",
    "        ))\n",
    "\n",
    "        # Break the loop if no more messages are returned\n",
    "        if not history.messages:\n",
    "            break\n",
    "\n",
    "        # Add image messages to the list\n",
    "        messages = history.messages\n",
    "        for msg in messages:\n",
    "            if isinstance(msg.media, MessageMediaPhoto):\n",
    "                # Download the image to the specified directory\n",
    "                image_file = await client.download_media(msg, output_directory)\n",
    "                \n",
    "                if image_file:  # If the image is successfully downloaded\n",
    "                    all_images.append({\n",
    "                        'ID': msg.id,\n",
    "                        'Date': msg.date,\n",
    "                        'Image Path': image_file\n",
    "                    })\n",
    "\n",
    "        # Update the offset_id to the last message's ID to avoid duplicates\n",
    "        offset_id = messages[-1].id\n",
    "\n",
    "        # Sleep to respect Telegram's rate limit\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    # Limit the number of images to max_images\n",
    "    all_images = all_images[:max_images]\n",
    "\n",
    "    # Convert to DataFrame and save to CSV\n",
    "    df = pd.DataFrame(all_images)\n",
    "    df.to_csv(r'C:\\Users\\Yibabe\\Desktop\\10academykifiyaAIMweek-7\\data\\image1.csv', index=False)\n",
    "    print(\"Scraping complete. Image data saved to 'image_messages.csv'.\")\n",
    "\n",
    "# Main function to run the scraping\n",
    "async def main():\n",
    "    await client.start()  # Start the client\n",
    "    await scrape_image_messages('@CheMed123', max_images=10000, batch_size=100, sleep_time=0.2)\n",
    "\n",
    "# Run the main function\n",
    "await main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
